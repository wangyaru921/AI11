# å¥³æœ‹å‹
# 1ã€aiå¾—çŸ¥é“ä»–æ˜¯ä½ çš„å¥³æœ‹å‹ langchainä¸­æç¤ºè¯æ¨¡å—æ¥é™å®š
#    å¥³æœ‹å‹çš„æ€§æ ¼å’Œç±»å‹ç”±ç”¨æˆ·é€‰æ‹©
# 2ã€aiè¿˜èƒ½èƒ½è®°ä½ç”¨æˆ·å’Œå®ƒèŠå¤©çš„è®°å½•
#    langchainçš„memoryè®°å¿†æ¨¡å—æ¥å®ç°
# 3ã€éœ€è¦ä½¿ç”¨langchainçš„chainé“¾ï¼Œé“¾æŠŠæç¤ºè¯+æ¨¡å‹+è®°å¿†è¿æ¥èµ·æ¥
# æ„å»ºæˆ‘ä»¬çš„æç¤ºè¯ï¼Œé€šè¿‡æç¤ºè¯æ¥ç»™å¤§æ¨¡å‹å®šä¹‰è§„åˆ™
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory # åœ¨å†…å­˜ä¸­ä¿å­˜å†å²è®°å¿†çš„æ¨¡å—
from langchain.chains import ConversationChain
import data.data as dd
import model.model as mm
import pages.bg as bg

user_id = st.session_state.user_id  # ç”¨æˆ·idå°±æ˜¯æŸä¸€ä¸ªç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†
username = st.session_state.username
st.title('æˆ‘çš„çŸ¥å¿ƒæœ‹å‹â¤ï¸â¤ï¸ğŸ’•â¤ï¸ğŸ’•')
st.subheader("åŸæ¥æ˜¯ä½ ï¼Œé«˜å±±æµæ°´è§…çŸ¥éŸ³")
if "gms" not in st.session_state:
    st.session_state.gms =[]

for gm in st.session_state.gms:
    with st.chat_message(gm["role"]):
        st.write(gm["context"])

list = dd.query_message_by_user_id_friends(user_id=user_id)
if list:
    # {"message_id":xx,"user_id":xx,message:xxx,role:xxx,message_time:xxx"}
    for msg in list:
        with st.chat_message(msg["role"]):
            st.write(msg["message"])
else:
    # å¦‚æœå½“å‰ç”¨æˆ·å’ŒAIåŠ©æ‰‹æ²¡æœ‰ä»»ä½•çš„èŠå¤©è®°å½•ï¼Œéœ€è¦ç»™ä»–ä¸€ä¸ªé»˜è®¤çš„åŠ©æ‰‹æ¬¢è¿è¯­
    with st.chat_message("assistant"):
        st.write("æˆ‘æ˜¯ä½ çš„æ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¯ä»¥åƒæœ‹å‹ä¸€æ ·å’Œä½ èŠå¤©ï¼Ÿ")

# æ„å»ºçš„å¤§æ¨¡å‹
llm = ChatOpenAI(
    model="glm-4-0520",
    api_key="4e8359731127a629e7d20d4cfe2ffe23.rtG99jESZmNdEA7K",
    temperature=0.99,
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
# æ„å»ºè®°å¿†æ¨¡å—
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory()
# é€šè¿‡é“¾æŠŠä¸‰ä¸ªæ¨¡å—ç»™è¿æ¥èµ·æ¥
# ConversationChainé“¾ä¹‹æ‰€ä»¥èƒ½æ‰€ä»¥å†å²è®°å¿†å­˜å‚¨ï¼Œä¸»è¦æ˜¯å› ä¸ºä¼šåšä¸€ä»¶äº‹æƒ…ï¼Œä¼šæŠŠmemoryè®°å¿†æ¨¡å—ä¸­çš„æ•°æ®ä»¥historyå‚æ•°åçš„å½¢å¼
# å°è£…åˆ°é“¾çš„PromptTemplateæç¤ºè¯æ¨¡æ¿å½“ä¸­
temp = "ç°åœ¨ä½ è¦æ‰®æ¼”ä¸€ä¸ªæœ‹å‹çš„è§’è‰²ï¼Œä½ çš„æ€§æ ¼æ˜¯"+st.session_state.xingge+"ï¼Œä½ åªéœ€è¦å›ç­”ä½ æœ‹å‹çš„è¯å³å¯ï¼Œä¸éœ€è¦é‡å¤ç”¨æˆ·çš„è¯ï¼Œä¹Ÿä¸è¦åŠ è¡¨æƒ…ï¼Œä¹Ÿä¸éœ€è¦å°†ä½ çš„è§’è‰²å’Œæ€§æ ¼è¿›è¡Œå±•ç¤ºã€‚ä½ çš„æœ‹å‹è¯´çš„è¯æ˜¯:{input},ä½ ä»¬çš„ä»¥å‰çš„å¯¹è¯æ˜¯{history}"
prompt = PromptTemplate(
    input_variables=["input","history"],
    template=temp
)
chain = ConversationChain(
    prompt=prompt,
    llm=llm,
    memory=st.session_state.memory
)

input = st.chat_input("å’Œä½ çš„æœ‹å‹è¯´ç‚¹è¯å§")
if input:
    with st.chat_message("user"):
        st.write(input)
        dd.add_chat_message_friends(user_id, input, "user")
        res = mm.invoke(input)
    st.session_state.gms.append({"role":"user","context":input})
    # è°ƒç”¨å¤§æ¨¡å‹å›ç­”æˆ‘ä»¬çš„é—®é¢˜
    result = chain.invoke(input)
    # å¸¦æœ‰è®°å¿†çš„é“¾resultä¸­æ²¡æœ‰content,
    with st.chat_message("assistant"):
        st.write(result["response"])
        dd.add_chat_message_friends(user_id, res, "assistant")
    st.session_state.gms.append({"role":"assistant","context":result["response"]})
bg.main_bg('1.png')
